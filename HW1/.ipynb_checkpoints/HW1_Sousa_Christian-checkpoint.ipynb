{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "\n",
    "# Homework 1: Data Cleaning and Exploratory Data Analysis \n",
    "***\n",
    "\n",
    "**Name**: \n",
    "\n",
    "***\n",
    "\n",
    "This assignment is due on Canvas by **11:59 PM on Friday January 31**. Your solutions to theoretical questions should be done in Markdown directly below the associated question.  Your solutions to computational questions should include any specified Python code and results as well as written commentary on your conclusions.  Remember that you are encouraged to discuss the problems with your classmates, but **you must write all code and solutions on your own**.\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Any relevant data sets should be available under the **Data** module on Canvas. \n",
    "- If you're not familiar with typesetting math directly into Markdown then by all means, do your work on paper first and then typeset it later.  Remember that there is a [reference guide](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference) linked on Canvas on writing math in Markdown. **All** of your written commentary, justifications and mathematical work should be in Markdown.\n",
    "- Because you can technically evaluate notebook cells is a non-linear order, it's a good idea to do Kernel $\\rightarrow$ Restart & Run All as a check before submitting your solutions.  That way if we need to run your code you will know that it will work as expected. \n",
    "- It is **bad form** to make your reader interpret numerical output from your code.  If a question asks you to compute some value from the data you should show your code output **AND** write a summary of the results in Markdown directly below your code. \n",
    "- This probably goes without saying, but... For any question that asks you to calculate something, you **must show all work and justify your answers to receive credit**. Sparse or nonexistent work will receive sparse or nonexistent credit. \n",
    "\n",
    "---\n",
    "**Shortcuts:**  [Problem 1](#p1) | [Problem 2](#p2) | [Problem 3](#p3) | [Problem 4](#p4) | [Problem 5](#p5) \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "\n",
    "<br>\n",
    "\n",
    "<a/ id='p1'></a>\n",
    "\n",
    "### (10 points) Problem 1\n",
    "***\n",
    "\n",
    "<img style=\"float: left; width: 200px; padding: 3mm;\" src=\"https://aquarium.org/wp-content/uploads/2015/08/Seahorse-female.jpg\" alt=\"Drawing\"/>  \n",
    "Poseidon is studying seahorses. Locations in each of the Atlantic, Pacific, Indian, Artic, and Southern Oceans are chosen to catch and release seahorses. After being caught, the seahorses are monitored for 24 hours while being fed organic, free-range plankton. The amount of plankton that each seahorse eats is recorded in an app on Poseidon’s phone, called Hippocampus. He collects 6 seahorses from the Arctic Ocean, 36 seahorses from the Pacific Ocean, 12 seahorses from the Indian Ocean, 6 seahorses from the Southern Ocean, and 42 seahorses from the Atlantic Ocean. \n",
    "\n",
    "Poseidon wants to get a sense for the average amount of plankton eaten by seahorses, so he uses the Hippcampus app to first order the seahorses in terms of when each seahorse was caught (first caught to last caught). Then, he selects every 3rd seahorse to see how much plankton was eaten.\n",
    "\n",
    "$$ \\quad $$\n",
    "    \n",
    "**Part A:** Identify the following: <br>\n",
    "<br>\n",
    "\n",
    "- the population \n",
    "- the sample frame \n",
    "- the sample \n",
    "- the type of sample \n",
    "- the quantity of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Population:**\n",
    "    given that the population is defined to be the entire data set (ie, all the seahorses that were collected). so to find out our population we add up how many seahorses were caught from each ocean:<br>\n",
    "    $6+36+12+6+42= 102$<br>\n",
    "    Therefore our population is **102 seahorses**.\n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "**Sample frame:**\n",
    "    A sample frame is defined as the method of selecting the sampel, which in this case is the hippocampus app as it is used to decide which seahorse's data are to be used.<br>\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "**Sample:**\n",
    "    The sample is the subset of the population who's data is being used. In this case the sample is the subset of every third seahorse that is caught and evaluated. the size of the sampel is 34 as: <br>\n",
    "    \n",
    "$102/3=34$\n",
    "\n",
    "\n",
    "\n",
    "**Type of Sample:**\n",
    "    Because the seahorses are \"counted off\" I would say that this is sytematic sampling.\n",
    "    \n",
    "**Quantity of Interest:**\n",
    "    Here what we are looking for is the number of plankton that the seahorses eat. Therefore, this the quantity of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "\n",
    "<br>\n",
    "\n",
    "<a/ id='p2'></a>\n",
    "\n",
    "### (25 points) Problem 2\n",
    "***\n",
    "\n",
    "A method to investigate the sensitivity of the sample mean and sample median to extreme outliers and changes in the dataset is to replace one or more elements in a given dataset by a number $y$ and investigate the effect when $y$ changes. To illustrate this, consider the following dataset:\n",
    " \n",
    "$$  4.3 \\quad 5.2 \\quad 5.0 \\quad 3.8 \\quad 4.1 \\quad 5.5 \\quad 1.9 $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A:** Compute the sample mean and sample median. Do not use the canned mean and median python functions. Write your own code to compute these quantities. You may use the python length and sort functions, but that is it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my calculated mean is: 4.257142857142857\n",
      "my calculated median is: 4.3\n"
     ]
    }
   ],
   "source": [
    "a= [4.3, 5.2, 5.0, 3.8, 4.1, 5.5, 1.9]\n",
    "a= np.sort(a)\n",
    "mean =(sum(a)/7)\n",
    "print(\"my calculated mean is:\", mean)\n",
    "median= a[int(len(a)/2)]\n",
    "print(\"my calculated median is:\", median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B:** Now, recompute the mean and the median using the python numpy functions. Compare your answers to what you computed in Part A. Do your answer match? (Hint: They should!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mean is:  4.257142857142857\n",
      "the median is:  4.3\n"
     ]
    }
   ],
   "source": [
    "a= [4.3, 5.2, 5.0, 3.8, 4.1, 5.5, 1.9]\n",
    "mean= np.mean(a)\n",
    "a= np.sort(a)\n",
    "#print(a)\n",
    "median= np.median(a)\n",
    "print(\"the mean is: \",mean)\n",
    "print(\"the median is: \", median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see both my calculation and python calculation come to the same thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C:** Now consider the following data set. \n",
    "$$  4.3 \\quad 5.2 \\quad 5.0 \\quad 3.8 \\quad 4.1 \\quad 5.5 \\quad 1.9 \\quad y$$\n",
    "\n",
    "Is there a value for $y$ that would make the mean of the data equal to 7? If so, calculate the value of $y$ that makes the mean equal to 7. If not, clearly explain why not.\n",
    "    \n",
    "Is there a value for $y$ that would make the median of the data equal to 7? If so, calculate the values of $y$ that makes the median equal to 7. If not, clearly explain why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "Yes, It is possible to add a singluar number to the data set such that the mean is 7. We have to start by looking at how the mean is calculated. Let A signify the data set not including y.\n",
    "\n",
    "$Mean= (Sum(A)+y)/len(A)$<br>\n",
    "\n",
    "If we now set the mean to 7 we can solve for y \n",
    "\n",
    "$7 \\times len(A)= Sum(A) + Y$<br>\n",
    "$(7 \\times len(A))-Sum(A) = Y$<br>\n",
    "\n",
    "we now translate this into the python code that solves for y. When that is complete we can take that calculated y and add it into the data set and use the built in mean to check our work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the calculated y is:  19.200000000000003\n",
      "the calculated mean is 6.125\n"
     ]
    }
   ],
   "source": [
    "a= [4.3, 5.2, 5.0, 3.8, 4.1, 5.5, 1.9]\n",
    "y= 7*7 -sum(a)\n",
    "a.append(y)\n",
    "mean = np.mean(a)\n",
    "print(\"the calculated y is: \", y)\n",
    "print(\"the calculated mean is\", mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "In this particular case it is not possible to get the median to become 7 by adding a number. This is because the median is depdant on the ascending order. adding any one number would make the median a number in the data set, in fact it would make it the middle number in the data set. imagine we have the below list where y is the new number we are inputting (it might not go in that spot but jut roll with it for now).<br>\n",
    "$[1.9, 3.8, 4.3, 5.0, 5.2, 5.5, y]$<br>\n",
    "in this case the newmedian would be 5 (assumes y greater than 5.0). Because the \"central\" numbers in the original data set are not near 7 then it is no possible to add any number to shift the median left or right to equal 7. It is also impossible to insert the new number around the central number such that the mean become 7. This is because the central numbers are significantly(relivitve) less than 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No code for this explanation se the above written explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Compute the sample variance and the sample standard deviation for the original dataset given in part A using the formulas given in class. You may not use the built-in python variance, standard deviation, or sum functions. Using the length and square root functions is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sample variance is:  1.462857142857143\n",
      "the standard deviation is:  1.2094863136295273\n"
     ]
    }
   ],
   "source": [
    "a= [4.3, 5.2, 5.0, 3.8, 4.1, 5.5, 1.9]\n",
    "# we first need to calculate the mean\n",
    "mean=0\n",
    "for k in a:\n",
    "    mean = mean + k\n",
    "mean= mean/(len(a))\n",
    "s=0\n",
    "#print(mean)\n",
    "for k in a:\n",
    "    s= s+pow((k-mean),2)\n",
    "s= s*(1/(len(a)-1))\n",
    "print(\"the sample variance is: \", s)\n",
    "print(\"the standard deviation is: \", math.sqrt(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E:** Execute the following code. Does it match what you computed in part D? Why or why not? If not, how can you correct the code below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample variance is:  1.2538775510204085\n",
      "the std dev is:  1.1197667395580244\n"
     ]
    }
   ],
   "source": [
    "dataset = [4.3, 5.2, 5.0, 3.8, 4.1, 5.5, 1.9]\n",
    "print(\"The sample variance is: \", np.var(dataset))\n",
    "print(\"the std dev is: \", np.std(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample variance is:  1.4628571428571433\n",
      "the std dev is:  1.1197667395580244\n"
     ]
    }
   ],
   "source": [
    "# Your coddataset = [4.3, 5.2, 5.0, 3.8, 4.1, 5.5, 1.9]\n",
    "print(\"The sample variance is: \", np.var(dataset, ddof=1))# the ddof=1 specifed sample variance so var is calculated 1/(n-1)\n",
    "print(\"the std dev is: \", np.std(dataset, ddof=1))# the same applies here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F**: Again consider the data set from Part C: $$  4.3 \\quad 5.2 \\quad 5.0 \\quad 3.8 \\quad 4.1 \\quad 5.5 \\quad 1.9 \\quad y$$\n",
    "\n",
    "Compute the sample median for the following cases (you may use whatever built-in python functions you'd like): \n",
    "- $y=5$ \n",
    "- $y=50$ \n",
    "- $y=4.36$ \n",
    "- $y \\to \\infty$ \n",
    "- $y \\to -\\infty$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when y=5 the median=  4.65\n",
      "when y=50, the median= 4.65\n",
      "when y=4.36, the median=  4.33\n",
      "y= infinity, the median=  4.65\n",
      "y= -infinity, the median=  4.199999999999999\n"
     ]
    }
   ],
   "source": [
    "a= [4.3, 5.2, 5.0, 3.8, 4.1, 5.5, 1.9]\n",
    "\n",
    "#y=5\n",
    "a= [4.3, 5.2, 5.0, 3.8, 4.1, 5, 5.5, 1.9]\n",
    "print(\"when y=5 the median= \", np.median(a))\n",
    "#y=50\n",
    "a= [4.3, 5.2, 5.0, 3.8, 4.1, 5.5, 1.9, 50]\n",
    "print(\"when y=50, the median=\", np.median(a))\n",
    "#y= 4.36\n",
    "a= [4.3, 5.2, 5.0, 3.8, 4.1, 4.36, 5.5, 1.9]\n",
    "print(\"when y=4.36, the median= \", np.median(a))\n",
    "#y= infinity \n",
    "a= [4.3, 5.2, 5.0, 3.8, 4.1, 5.5, 1.9, math.inf]\n",
    "print(\"y= infinity, the median= \", np.median(a))\n",
    "a= [4.3, 5.2, 5.0, 3.8, 4.1, 5.5, 1.9, -math.inf]\n",
    "print(\"y= -infinity, the median= \", np.median(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part G**: Think about the previous parts, above, and describe in words or mathematical notation the answer to the following question:\n",
    "\n",
    "- By varying $y$, what is the set of all the possible values that the sample mean could take on?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part H**: Describe in words or mathematical notation, what happens to the sample standard deviation when $y$ is varied in the following ways: \n",
    " \n",
    "- $y \\to \\infty$ \n",
    "- $y \\to \\bar{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "\n",
    "<a/ id='p3'></a>\n",
    "\n",
    "## (25 pts) Problem 3\n",
    "*** \n",
    "Some claim that the final hours aboard the RMS Titanic were marked by \"class warfare\" in which the people with first-class tickets took all the good spots on the lifeboats; others claim that the final hours were characterized by male chivalry, in which the men valiantly gave up their positions in the boats and succumbed bravely to the depths of the Atlantic. \n",
    "\n",
    "We have the data on survival rates by class and by sex, so let's figure out whether there is evidence for these scenarios. Access the Titanic data in `titanic_data.csv` and store it in a Pandas DataFrame. The data contains information pertaining to class status (**Pclass**), survival (**Survived**), and gender (**Sex**) of passengers, among other things. Be sure to use the `titanic_data.csv` data set, *not* the `clean_titanic_data` file from the in-class notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  36.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  18.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  14.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  27.0      1   \n",
       "4                           Allen, Mr. William Henry    male  63.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'titanic_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Consider the two claims: class warfare, and male chivalry. Suppose that class warfare occurred in the final hours aboard the Titanic.  What patterns might you expect to see in the data?  Suppose that male chivalry was widespread during the final hours instead. What patterns might you then expect to see in the data?  Explain both of these hypothesized patterns in words. Are these two hypotheses mutually exclusive or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Use Pandas methods to create a clean data set by removing any rows from the DataFrame that are missing values corresponding to **Survived**, **Pclass**, **Age**, or **Sex**. Store the clean data in a DataFrame called dfTitanic. Be sure to show any exploratory work determining if/where there are rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Compute the fraction of survivors according to class and gender. There are 3 passenger classes and 2 sexes in the data set, so you should report all 6 possible combinations.  Then, answer 3 questions:\n",
    "* **(i)** Within each passenger class, were men or women more/less/equally likely to survive?\n",
    "* **(ii)**  Looking at only the male or only the female passengers, how is passenger class related to the category's survival rate?\n",
    "* **(iii)**  Did men in first class or women in third class have a higher survival rate? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Plot a histogram of all of the passenger ages, using the bin edges $[0,5,10,\\ldots,70,75,80]$ defined by `my_bins` below. How would you characterize the distribution of **AGE**? (By _characterize_ we mean that you should indicate whether the data are unimodal, bimodal, multimodal, symmetric, negatively skewed, positively skewed, etc.)  Be sure to label your axes and use your figure to justify your conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bins = range(0,85,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: One might wonder how a passenger's age is related to the likelihood that they would survive the Titanic disaster. To answer this question graphically, plot two density histograms on the same set of axes, showing the distribution of the ages of passengers who survived, and the distribution of the ages of passengers who did not. \n",
    "* Use the bin edges $[0,5,10,\\ldots,70,75,80]$ for both histograms.\n",
    "* This problem is about a *ship* sinking in the *ocean*, so use **coral** and **seagreen** as the facecolors for your histogram boxes.\n",
    "* Plot both histograms on a single set of axes (there should be only one panel in the figure you create), but use Matplotlib/Pandas plotting functionality to make the faces of the histogram boxes somewhat transparent, so both histograms are visible.\n",
    "* Include a legend and label your axes.\n",
    "* Comment on the results. Does your figure suggest that some age ranges are more or less likely to have survived the disaster than other ages? Fully explain your reasoning and use your figure to justify your conclusions.\n",
    "* If you noticed some relationship between age and likelihood of survival, what is one possible explanation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F:** In Part E, we plotted two *density* histograms, showing the distributions of ages of passengers that survived or did not survive the Titanic disaster. Why would it be misleading for us to have plotted these as *frequency* histograms instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part G**: Do the data suggest class warfare, male chivalry, or some combination of both characteristics in the final hours aboard the Titanic?  Justify your conclusion based on the computations done above, or do any other analysis that you like, but be sure to clearly justify your conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "<a/ id='p4'></a>\n",
    "\n",
    "## (25 pts) Problem 4 (Snowfall in Boulder)\n",
    "***\n",
    "\n",
    "The NOAA Earth System Research Laboratory (ESRL) Physical Sciences Division (PSD) conducts scientific research to observe, understand, model, predict, and forecast weather, water, and climate extremes and their impacts. They have a website with publicly available data. One such data set contains monthly snowfall for Boulder dating back to 1889 (https://www.esrl.noaa.gov/psd/boulder/bouldersnow.html). Load ‘Boulder_Snowfall.csv’ from the Canvas page. \n",
    "\n",
    "**Part A:** To start, we need to “clean” our data set. When the amount of snow was nonzero, but too small to be recorded, this data set recorded ‘T’. Replace those instances with zeros. AFTER, you've done that, remove any rows (which correspond to years) with missing data. As a check, if you've cleaned the file correctly, there should be 121 rows remaining. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B:** Plot the last column of data, “Total Jan-Dec”, from the cleaned data set. Label your axes. Do you observe any trends? Discuss.\n",
    "\n",
    "[Note: Make sure that your x-axis tick labels are in years and are readable. You may have to play around with formatting the ticklabels. plt.MaxNLocator might be helpful depending on how you plotted your data.] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C:** Using your cleaned data set, create a histogram of the yearly snowfall. Bin your data with a bin-width of 5 inches, starting at 35 inches. Make the edgecolor of your graph white. What is the most common amount of snow to get in a year? How does this compare with how much snow we got in 2019? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D:** Generate a series of 12 box plots to represent each decade starting in 1900, using your cleaned data set. Orient the box plots so that the decades (‘1900-1909’, ‘1910-1919’, … , ‘2010-2019’) appear along the x-axis, and the y-axis shows the amount of snowfall. Have all 12 boxplots as part of one graph. Include appropriate labels to your axes and a title, so that if someone not in our class were to look at your plots, they would understand what they were looking at. \n",
    "\n",
    "[Note: Data from the year 2004 was dropped during the initial cleaning of the data set (or should have been). Keep this in mind when plotting data from the 2000-2009 decade.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Part E:** It’s almost February, so let’s study snowfall in Boulder, in February. Compute the mean February snowfall using your cleaned data set. Next calculate the Tukey 5-number summary for the February snowfall data. Lastly, generate a boxplot for the February snowfall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F:** Plot all of the February snowfall with a line plot, using your cleaned data set. How many inches of snow do you predict we will get this February in Boulder? Once February is over, we’ll see who was the closest!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#top)\n",
    "<a/ id='p5'></a>\n",
    "\n",
    "## (15 pts) Problem 5\n",
    "***\n",
    "Consider the following 3 data sets:\n",
    "\n",
    "`A=[8, 6, 7, 5, 3, 0, 9]`\n",
    "\n",
    "`B=[2, 29, 84, 2, 10, 69, 3, 31, 18]`\n",
    "\n",
    "`C` is the random data set generated by using `np.random.randint(0,1000, size=100)`\n",
    "\n",
    "For each data set, perform the following computations:\n",
    "\n",
    "**Part A:** Compute and print the mean and standard deviation of the data set. You may use built-in python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B:** Compute and print  the mean and standard deviation of the new data set formed by subtracting the original mean from each observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C:** Compute and print  the mean and standard deviation of the new data set formed by subtracting the original mean from each observation and then dividing by the original standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D:** Why might this result matter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
